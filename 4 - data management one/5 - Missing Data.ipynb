{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning\n",
    "\n",
    "* Anywhere from 50% to 80% of data science is data cleaning\n",
    "    * of course I hear 70% of statistics are made up on the spot\n",
    "* Dealing with dirty data is a fact of life when doing data intensive research\n",
    "* Especially if you are collecting or creating the data yourself\n",
    "* Fortunately, Pandas is excellent at data cleaning and once you get the hang of it you might even enjoy it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Missing Values \n",
    "\n",
    "* One of challenges you may face when working with messy data are *missing* or **null** values \n",
    "* There are multiple conventions for representing null values when doing data science in Python\n",
    "* There is a Pythonic way using the `None` object\n",
    "* There is a Numpy/Pandas-y way using `NaN`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### None - Pythonic Missing Data\n",
    "\n",
    "* None is the standard way of representing nothing in plain python\n",
    "* It is useful, but it is also a complex data structure\n",
    "* It can be used in numeric and programmatic contexts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a numpy array of numbers and a null value represented by None\n",
    "some_numbers = np.array([1,None,3,4])\n",
    "some_numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Because numpy arrays (and pandas series/columns) all have to be the same data type, it will default to the most expressive and most inefficient data type for the array\n",
    "    * Note:  Pandas will automatically convert `None` to `Nan` so we use `np.array` here\n",
    "* This means any operations running over the array/column/series are going to run slower than they could if the data type was numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a list of objects and a list of integers\n",
    "# compute their sum and time how long it takes\n",
    "for dtype in ['object','int']:\n",
    "    print(\"data type = \", dtype)\n",
    "    %timeit np.arange(1E6, dtype=dtype).sum()\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Notice the integer array was ***a lot*** faster than the object array\n",
    "* Also, the vectorized math operations don't like `None`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_numbers.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NaN - Numpy/Pandas-y Missing Numeric data\n",
    "\n",
    "* The Numpy third-party library has a mechanism for representing missing numeric values\n",
    "* Under the hood, NaNs are a standards compliant floating point numbers \n",
    "    * Note for R users: There is no `Null` only `NaN`\n",
    "* This means you can use them with other numeric arrays for fast computations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a numeric Pandas Series with a missing value\n",
    "nanny = pd.Series([1, np.nan, 3, 4])\n",
    "nanny.dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now we can use all the fast and easy computations in Pandas without worring about missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the sum of all the numbers in the Series\n",
    "nanny.sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operating on Null Values\n",
    "\n",
    "* There are four functions in Pandas that are useful for working with missing data\n",
    "* The examples below operate on Series, but they can work on Dataframes as well\n",
    "\n",
    "\n",
    "### Null value functions\n",
    "\n",
    "* `isna()` - Generate a boolean mask of the missing values (can also use `isnull()`)\n",
    "* `notna()` - Do the opposite of `isna()` (can also use `notnull()`\n",
    "* `dropna()` - Create a filtered copy of the data with no null values\n",
    "* `fillna(value)` - Create a copy of the data will null values filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the Series\n",
    "nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what values are null\n",
    "nanny.isna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# what values are not null\n",
    "nanny.notna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These masks can be used to filter the data and create a view of missing or not missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not super useful in a Series, but handy with Dataframes\n",
    "nanny[nanny.isna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Rather than creating a view, we can create *copies* of the data with the null values removed or filled in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Just get rid of all the null values\n",
    "no_null_nanny = nanny.dropna()\n",
    "no_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the null values with zero\n",
    "fill_null_nanny = nanny.fillna(0)\n",
    "fill_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill in the null values with a different value\n",
    "fill_null_nanny = nanny.fillna(999)\n",
    "fill_null_nanny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The original nanny Series remains untouched #noreboot\n",
    "# Fran Drescher frowns with dissapointment \n",
    "nanny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* These functions work with dataframes as well\n",
    "* But you will need to pay closer attention to what it is doing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_nanny = pd.DataFrame([[1, np.nan, 2],\n",
    "                        [2, 3, 5],\n",
    "                        [np.nan, 4, 6]])\n",
    "df_nanny"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Dropping null values with `dropna()` removes the entire axis (row or column) and returns a new copy of the dataframe\n",
    "* You can specify dropping rows or columns with the axis parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropna gets rid of rows by default\n",
    "df_nanny.dropna() # axis=\"rows\" or axis=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use the axis=\"columns\" or axis=1 to drop columns\n",
    "df_nanny.dropna(axis=\"columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are a couple other parameters that let you specify other behaviors\n",
    "* Like only dropping rows/columns with all null values or settings a threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working with null values in real data\n",
    "\n",
    "* Here is an example of some real data, the diabetes data from week 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data file into a Pandas dataframe\n",
    "df = pd.read_csv(\"../2 - data python two/diabetes.csv\")\n",
    "\n",
    "# Display the first 5 rows of the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the metadata about the data, making sure to display null values\n",
    "df.info() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we look closely at this information we can see there are a few null values in this dataset\n",
    "* There are 403 rows, but some columns have less than 403 non-null values\n",
    "* Now let's check which values in the dataset are missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a boolean mask where True indicates a null value\n",
    "df.isna().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Gak! Too much data, how can we just get a quick count of the null values?\n",
    "* What if we combined `isnull()` with the `sum()` function?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the sum function to count the True values in the boolean mask\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* If we wanted to look at a specific column we can do the same operation \n",
    "* These functions work with Series as well as DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# How many null values in the chol column\n",
    "df[\"chol\"].isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Now let's deal with missing values\n",
    "* Solution 1: Remove rows with empty values\n",
    "* If there are only a few null values and you know that deleting values will not cause adverse effects on your result, remove them from your DataFrame\n",
    "* Make sure to save the new dataframe to a new variable!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display missing value counts\n",
    "print(\"Missing values before dropping rows: \")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "\n",
    "# Display new dataset\n",
    "mod_df = df.dropna() # make a copy of the dataframe with null values removed\n",
    "print(\"Missing values after dropping rows: \")\n",
    "print(mod_df.isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
